{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '../datasets/raw/'\n",
    "train_users = pd.read_csv(path + 'train_users.csv')\n",
    "test_users = pd.read_csv(path + 'test_users.csv')\n",
    "sessions = pd.read_csv(path + 'sessions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_users = train_users.head(200)\n",
    "test_users = test_users.head(200)\n",
    "sessions = sessions.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of train user for latter splitting\n",
    "train_users_length = len(train_users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join users\n",
    "users = pd.concat((train_users, test_users), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop useless column\n",
    "users = users.drop('date_first_booking', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace NaNs\n",
    "users['gender'].replace('-unknown-', np.nan, inplace=True)\n",
    "users['language'].replace('-unknown-', np.nan, inplace=True)\n",
    "sessions.replace('-unknown-', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove weird age values\n",
    "users.loc[users['age'] > 100, 'age'] = np.nan\n",
    "users.loc[users['age'] < 14, 'age'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List categorical features\n",
    "categorical_features = [\n",
    "    'affiliate_channel',\n",
    "    'affiliate_provider',\n",
    "    'country_destination',\n",
    "    'first_affiliate_tracked',\n",
    "    'first_browser',\n",
    "    'first_device_type',\n",
    "    'gender',\n",
    "    'language',\n",
    "    'signup_app',\n",
    "    'signup_method'\n",
    "]\n",
    "\n",
    "# Change categorical features\n",
    "for categorical_feature in categorical_features:\n",
    "    users[categorical_feature] = users[categorical_feature].astype('category')\n",
    "\n",
    "# Change type to date\n",
    "users['date_account_created'] = pd.to_datetime(users['date_account_created'])\n",
    "users['date_first_active'] = pd.to_datetime(users['timestamp_first_active'],\n",
    "                                            format='%Y%m%d%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users['date_first_active'] = pd.to_datetime(users['timestamp_first_active'],\n",
    "                                            format='%Y%m%d%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute date_account_created weekday\n",
    "weekdays = []\n",
    "for date in users.date_account_created:\n",
    "    weekdays.append(date.weekday())\n",
    "users['weekday_account_created'] = pd.Series(weekdays)\n",
    "\n",
    "# Compute weekday_first_active weekday\n",
    "weekdays = []\n",
    "for date in users.date_account_created:\n",
    "    weekdays.append(date.weekday())\n",
    "users['weekday_first_active'] = pd.Series(weekdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dates into day,month,year\n",
    "users['year_account_created'] = pd.DatetimeIndex(users['date_account_created']).year\n",
    "users['month_account_created'] = pd.DatetimeIndex(users['date_account_created']).month\n",
    "users['day_account_created'] = pd.DatetimeIndex(users['date_account_created']).day\n",
    "users['year_first_active'] = pd.DatetimeIndex(users['date_first_active']).year\n",
    "users['month_first_active'] = pd.DatetimeIndex(users['date_first_active']).month\n",
    "users['day_first_active'] = pd.DatetimeIndex(users['date_first_active']).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The constant N it's used to limit the values we get from the session data.\n",
    "N = 3\n",
    "\n",
    "for user in sessions['user_id'].unique()[0:40]:\n",
    "    # Get the user session\n",
    "    user_session = sessions.loc[sessions['user_id'] == user]\n",
    "\n",
    "    # Length of the session\n",
    "    users.loc[users['id'] == user, 'session_length'] = int(len(user_session))\n",
    "\n",
    "    # Save the number of times the user repeated his N top action_types\n",
    "    action_type = user_session['action_type'].value_counts()\n",
    "    for i in range(min(N, len(action_type.index))):\n",
    "        new_column = action_type.index[i] + '_count'\n",
    "        users.loc[users['id'] == user, new_column] = action_type.values[i]\n",
    "\n",
    "    # Count numer of times the user repeated his top N actions\n",
    "    action = user_session['action'].value_counts()\n",
    "    for i in range(min(N, len(action.index))):\n",
    "        new_column = action.index[i] + '_count'\n",
    "        users.loc[users['id'] == user, new_column] = action.values[i]\n",
    "\n",
    "    # The same with action detail\n",
    "    action_detail = user_session['action_detail'].value_counts()\n",
    "    for i in range(min(N, len(action_detail.index))):\n",
    "        new_column = action_detail.index[i] + '_count'\n",
    "        users.loc[users['id'] == user, new_column] = action_detail.values[i]\n",
    "\n",
    "    # Get the most used device\n",
    "    if user_session['device_type'].value_counts().sum() is not 0:\n",
    "        most_used_device = user_session['device_type'].value_counts().index[0]\n",
    "        users.loc[users['id'] == user, 'most_used_device'] = most_used_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove columns with a lot of NaNs\n",
    "to_remove = users.isnull().sum().loc[users.isnull().sum() > 275542].index\n",
    "users.drop(to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = users.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Elapsed seconds sum\n",
    "elapsed_secs_sum = sessions.groupby('user_id')['secs_elapsed'].sum()\n",
    "elapsed_secs_sum.name = 'elapsed_secs_sum'\n",
    "users = pd.concat([users, elapsed_secs_sum], axis=1)\n",
    "\n",
    "# Elapsed seconds mean\n",
    "elapsed_secs_average = sessions.groupby('user_id')['secs_elapsed'].mean()\n",
    "elapsed_secs_average.name = 'elapsed_secs_average'\n",
    "users = pd.concat([users, elapsed_secs_average], axis=1)\n",
    "\n",
    "# Elapsed seconds min\n",
    "min_secs_elapsed = sessions.groupby('user_id')['secs_elapsed'].min()\n",
    "min_secs_elapsed.name = 'min_secs_elapsed'\n",
    "users = pd.concat([users, min_secs_elapsed], axis=1)\n",
    "\n",
    "# Elapsed seconds max\n",
    "max_secs_elapsed = sessions.groupby('user_id')['secs_elapsed'].max()\n",
    "max_secs_elapsed.name = 'max_secs_elapsed'\n",
    "users = pd.concat([users, max_secs_elapsed], axis=1)\n",
    "\n",
    "# Elapsed seconds first_quantile\n",
    "first_quantile = sessions.groupby('user_id')['secs_elapsed'].quantile(0.25)\n",
    "first_quantile.name = 'first_quantile'\n",
    "users = pd.concat([users, first_quantile], axis=1)\n",
    "\n",
    "# Elapsed seconds second_quantile\n",
    "second_quantile = sessions.groupby('user_id')['secs_elapsed'].quantile(0.5)\n",
    "second_quantile.name = 'second_quantile'\n",
    "users = pd.concat([users, second_quantile], axis=1)\n",
    "\n",
    "# Elapsed seconds third_quantile\n",
    "third_quantile = sessions.groupby('user_id')['secs_elapsed'].quantile(0.75)\n",
    "third_quantile.name = 'third_quantile'\n",
    "users = pd.concat([users, third_quantile], axis=1)\n",
    "\n",
    "# Elapsed seconds fourth_quantile\n",
    "fourth_quantile = sessions.groupby('user_id')['secs_elapsed'].quantile(0.9)\n",
    "fourth_quantile.name = 'fourth_quantile'\n",
    "users = pd.concat([users, fourth_quantile], axis=1)\n",
    "\n",
    "# Elapsed seconds median\n",
    "median = sessions.groupby('user_id')['secs_elapsed'].median()\n",
    "median.name = 'elapsed_secs_median'\n",
    "users = pd.concat([users, median], axis=1)\n",
    "\n",
    "# Elapsed seconds std\n",
    "std = sessions.groupby('user_id')['secs_elapsed'].std()\n",
    "std.name = 'elapsed_secs_std'\n",
    "users = pd.concat([users, std], axis=1)\n",
    "\n",
    "# Elapsed seconds var\n",
    "var = sessions.groupby('user_id')['secs_elapsed'].var()\n",
    "var.name = 'elapsed_secs_var'\n",
    "users = pd.concat([users, var], axis=1)\n",
    "\n",
    "# Elapsed seconds skew\n",
    "skew = sessions.groupby('user_id')['secs_elapsed'].skew()\n",
    "skew.name = 'elapsed_secs_skew'\n",
    "users = pd.concat([users, skew], axis=1)\n",
    "\n",
    "# Number of elapsed seconds greater than 1 day\n",
    "day_pauses = sessions.loc[sessions['secs_elapsed'] > 86400].groupby('user_id').count()['secs_elapsed']\n",
    "day_pauses.name = 'day_pauses'\n",
    "users = pd.concat([users, day_pauses], axis=1)\n",
    "\n",
    "# Number of elapsed seconds lesser than 1 hour\n",
    "short_sessions = sessions.loc[sessions['secs_elapsed'] < 3600].groupby('user_id').count()['secs_elapsed']\n",
    "short_sessions.name = 'short_sessions'\n",
    "users = pd.concat([users, short_sessions], axis=1)\n",
    "\n",
    "# Users not returning in a big time\n",
    "long_sessions = sessions.loc[sessions['secs_elapsed'] > 300000].groupby('user_id').count()['secs_elapsed']\n",
    "long_sessions.name = 'long_sessions'\n",
    "users = pd.concat([users, long_sessions], axis=1)\n",
    "\n",
    "# First value\n",
    "first_secs_elapsed = sessions.groupby('user_id')['secs_elapsed'].first()\n",
    "first_secs_elapsed.name = 'first_secs_elapsed'\n",
    "users = pd.concat([users, first_secs_elapsed], axis=1)\n",
    "\n",
    "# Last value\n",
    "last_secs_elapsed = sessions.groupby('user_id')['secs_elapsed'].last()\n",
    "last_secs_elapsed.name = 'last_secs_elapsed'\n",
    "users = pd.concat([users, last_secs_elapsed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_users = train_users.set_index('id')\n",
    "test_users = test_users.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_train_users = users.loc[train_users.index]\n",
    "processed_test_users = users.loc[test_users.index]\n",
    "processed_test_users.drop('country_destination', inplace=True, axis=1)\n",
    "\n",
    "processed_train_users.to_csv('semi_processed_train_users.csv')\n",
    "processed_test_users.to_csv('semi_processed_test_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_list = [\n",
    "    'date_account_created',\n",
    "    'date_first_active',\n",
    "    'timestamp_first_active'\n",
    "]\n",
    "\n",
    "# Drop columns\n",
    "users = users.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "categorical_features = [\n",
    "    'gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel',\n",
    "    'affiliate_provider', 'first_affiliate_tracked', 'signup_app',\n",
    "    'first_device_type', 'first_browser', 'most_used_device'\n",
    "]\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.preprocessing import one_hot_encoding\n",
    "users = one_hot_encoding(users, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users.index.name = 'id'\n",
    "processed_train_users = users.loc[train_users.index]\n",
    "processed_test_users = users.loc[test_users.index]\n",
    "processed_test_users.drop('country_destination', inplace=True, axis=1)\n",
    "\n",
    "processed_train_users.to_csv('processed_train_users.csv')\n",
    "processed_test_users.to_csv('processed_test_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users.to_csv('users.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
