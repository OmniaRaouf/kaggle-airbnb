{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Multiclass and multilabel classification strategies.\n",
    "\n",
    "This file implements an one-vs-one multiclass learning algorithm that uses\n",
    "over sampling algorithms and variances of the decision function.\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import _fit_binary, check_is_fitted\n",
    "from sklearn.multiclass import _ovr_decision_function, _predict_binary\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from utils.unbalanced_dataset import SMOTE, SMOTEENN, OverSampler\n",
    "from utils.unbalanced_dataset import UnderSampler, TomekLinks\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def _score_matrix(probabilities, n_classes):\n",
    "    \"\"\"Create a probability matrix representing the probability of each class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    probabilities : array, shape = [n_classifiers]\n",
    "        Vector containing the predicted probabilities for the positive class\n",
    "        for each classifier.\n",
    "    n_classes : int\n",
    "        Number of classes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    probability_matrix : array of shape = [n_classes, n_classes]\n",
    "        The class probabilities of the input sample as an antisymetric matrix.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> probabilities = [0.9, 0.8, 0.2, 0.5, 0.3, 0.1]\n",
    "    >>> _score_matrix(probabilities, 4)\n",
    "    array([[ 0. ,  0.9,  0.8,  0.2],\n",
    "           [ 0.1,  0. ,  0.5,  0.3],\n",
    "           [ 0.2,  0.5,  0. ,  0.1],\n",
    "           [ 0.8,  0.7,  0.9,  0. ]])\n",
    "    \"\"\"\n",
    "    # Make empty matrix\n",
    "    matrix = np.zeros((n_classes, n_classes))\n",
    "\n",
    "    # Fill upper triangle with the vector\n",
    "    matrix[np.triu_indices(n_classes, 1)] = probabilities\n",
    "\n",
    "    # Fill lower triangle with the difference to one of the upper one\n",
    "    for i in range(n_classes):\n",
    "        for j in range(i, n_classes):\n",
    "            matrix[j][i] = 1 - matrix[i][j]\n",
    "\n",
    "    # Set diagonal to zero\n",
    "    np.fill_diagonal(matrix, 0)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def _sample_values(X, y, method=None, ratio=1, verbose=False):\n",
    "    \"\"\"Perform any kind of sampling(over and under).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape = [n_samples, n_features]\n",
    "        Data.\n",
    "    y : array, shape = [n_samples]\n",
    "        Target.\n",
    "    method : str, optional default: None\n",
    "        Over or under smapling method.\n",
    "    ratio: float\n",
    "        Unbalanced class ratio.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X, y : tuple\n",
    "        Sampled X and y.\n",
    "    \"\"\"\n",
    "    # TODO: Add kwargs\n",
    "    if method == 'SMOTE':\n",
    "        sampler = SMOTE(ratio=ratio, verbose=verbose)\n",
    "\n",
    "    elif method == 'SMOTEENN':\n",
    "        ratio = ratio * 0.3\n",
    "        sampler = SMOTEENN(ratio=ratio, verbose=verbose)\n",
    "\n",
    "    elif method == 'random_over_sample':\n",
    "        sampler = OverSampler(ratio=ratio, verbose=verbose)\n",
    "\n",
    "    elif method == 'random_under_sample':\n",
    "        sampler = UnderSampler(verbose=verbose)\n",
    "\n",
    "    elif method == 'TomekLinks':\n",
    "        sampler = TomekLinks(verbose=verbose)\n",
    "\n",
    "    return sampler.fit_transform(X, y)\n",
    "\n",
    "\n",
    "def _fit_ovo_binary(estimator, X, y, i, j, sampling=None, verbose=False):\n",
    "    \"\"\"Fit a single binary estimator (one-vs-one).\"\"\"\n",
    "    cond = np.logical_or(y == i, y == j)\n",
    "    y = y[cond]\n",
    "    y_binary = np.empty(y.shape, np.int)\n",
    "    y_binary[y == i] = 0\n",
    "    y_binary[y == j] = 1\n",
    "    ind = np.arange(X.shape[0])\n",
    "\n",
    "    X_values = X[ind[cond]]\n",
    "    y_values = y_binary\n",
    "\n",
    "    if sampling:\n",
    "        ones = np.count_nonzero(y_values == 1)\n",
    "        zeros = np.count_nonzero(y_values == 0)\n",
    "\n",
    "        # Class inbalancing ratio\n",
    "        ratio = abs(ones - zeros) / min(ones, zeros)\n",
    "\n",
    "        # Sample X and y\n",
    "        X_values, y_values = _sample_values(\n",
    "            X_values, y_values, method=sampling, ratio=ratio)\n",
    "\n",
    "    return _fit_binary(estimator, X_values, y_values, classes=[i, j])\n",
    "\n",
    "\n",
    "class CustomOneVsOneClassifier(OneVsOneClassifier):\n",
    "    \"\"\"One-vs-one multiclass strategy.\n",
    "\n",
    "    This strategy consists in fitting one classifier per class pair.\n",
    "    At prediction time, the class which received the most votes is selected.\n",
    "\n",
    "    Requires to fit `n_classes * (n_classes - 1) / 2` classifiers.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    estimators_ : list of `n_classes * (n_classes - 1) / 2` estimators\n",
    "        Estimators used for predictions.\n",
    "    classes_ : numpy array of shape [n_classes]\n",
    "        Array containing labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimator, n_jobs=1, sampling=None,\n",
    "                 strategy='vote', verbose=False):\n",
    "        \"\"\"Init method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator : estimator object\n",
    "            An estimator object implementing fit and one of decision_function\n",
    "            or predict_proba.\n",
    "        n_jobs : int, optional, default: 1\n",
    "            The number of jobs to use. If -1 all CPUs are used.\n",
    "            If 1 is given, no parallel computing code is used at all, which is\n",
    "            useful for debugging. For n_jobs below -1, (n_cpus + 1 + n_jobs)\n",
    "            are used. Thus for n_jobs = -2, all CPUs but one are used.\n",
    "        sampling : str, optional default: None\n",
    "            Samplig method to use when fitting each estimator.\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.n_jobs = n_jobs\n",
    "        self.sampling = sampling\n",
    "        self.verbose = verbose\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities for X.\n",
    "\n",
    "        The predicted class probabilities of an input sample is the same as\n",
    "        the result of decision_function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
    "            such arrays if n_outputs > 1.\n",
    "            The class probabilities of the input samples.\n",
    "        \"\"\"\n",
    "        return self.decision_function(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit underlying estimators.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : (sparse) array-like, shape = [n_samples, n_features]\n",
    "            Data.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Multi-class targets.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        valid_strategies = ('vote', 'weighted_vote',\n",
    "                            'dynamic_vote', 'relative_competence')\n",
    "        if self.strategy not in valid_strategies:\n",
    "            raise ValueError('Strategy %s is not valid.' % (self.strategy))\n",
    "\n",
    "        valid_sampling_methods = ('SMOTE', 'SMOTEENN', 'random_over_sample',\n",
    "                                  'random_under_sample', 'TomekLinks', None)\n",
    "        if self.sampling not in valid_sampling_methods:\n",
    "            raise ValueError('Sampling %s is not valid.' % (self.sampling))\n",
    "\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_classes = self.classes_.shape[0]\n",
    "\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_ovo_binary)(\n",
    "                self.estimator, X, y, self.classes_[i], self.classes_[j],\n",
    "                sampling=self.sampling, verbose=self.verbose\n",
    "            ) for i in range(n_classes) for j in range(i + 1, n_classes))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Decision function for the CustomOneVsOneClassifier.\n",
    "\n",
    "        By default, the decision values for the samples are computed by adding\n",
    "        the normalized sum of pair-wise classification confidence levels to the\n",
    "        votes in order to disambiguate between the decision values when the\n",
    "        votes for all the classes are equal leading to a tie.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Y : array-like, shape = [n_samples, n_classes]\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'estimators_')\n",
    "\n",
    "        predictions = np.vstack([est.predict(X) for est in self.estimators_]).T\n",
    "        confidences = np.vstack([_predict_binary(est, X)\n",
    "                                 for est in self.estimators_]).T\n",
    "\n",
    "        n_clases = len(self.classes_)\n",
    "\n",
    "        if self.strategy in ('weighted_vote', 'dynamic_vote',\n",
    "                             'relative_competence'):\n",
    "            # Compute matrix with classes probabilities\n",
    "            scores = [_score_matrix(c, n_clases) for c in confidences]\n",
    "\n",
    "            if self.strategy == 'dynamic_vote':\n",
    "                scores = self._dynamic_ovo(scores, X, n_clases)\n",
    "\n",
    "            elif self.strategy == 'relative_competence':\n",
    "                raise NotImplementedError('Strategy %s not implemented.'\n",
    "                                          % (self.strategy))\n",
    "\n",
    "            # Sum of each probability column representing each class\n",
    "            votes = np.vstack([np.sum(m, axis=0) for m in scores])\n",
    "\n",
    "            return votes\n",
    "\n",
    "        elif self.strategy == 'vote':\n",
    "            return _ovr_decision_function(predictions, confidences,\n",
    "                                          n_clases)\n",
    "\n",
    "    def _dynamic_ovo(self, scores, x, n_classes):\n",
    "        \"\"\"Dynamic One vs One classifier selection strategy.\n",
    "\n",
    "        Dynamic classifier selection strategy for One vs One scheme tries to\n",
    "        avoid the non-competent classifiers when their output is probably not\n",
    "        of interest considering the neighborhood of each instance to decide\n",
    "        whether a classifier may be competent or not.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        Mikel Galar, Alberto Fernandez, Edurne Barrenechea, Humberto Bustince,\n",
    "        and Francisco Herrera. Dynamic classifier selection for One-vs-One\n",
    "        strategy: Avoiding non-competent classifiers. 2013.\n",
    "        \"\"\"\n",
    "        # Select all the neighborhood\n",
    "        k = n_classes * 6\n",
    "\n",
    "        # Fit the training data\n",
    "        neigh = NearestNeighbors(n_neighbors=k, n_jobs=-1)\n",
    "        neigh.fit(self.X)\n",
    "\n",
    "        # Compute the indices of the k neighbors for x\n",
    "        n = neigh.kneighbors(x, return_distance=False)\n",
    "\n",
    "        # Get the unique classes of each neighbors\n",
    "        c = map(self._get_neighbors_classes, n)\n",
    "\n",
    "        # Select the column classes in the score matrices\n",
    "        # that appears into the neighborhood.\n",
    "        for i, score in enumerate(scores):\n",
    "\n",
    "            # If there is only one class, return the same score\n",
    "            # matrix as this sample will be properly classified\n",
    "            if len(c[i]) == 1:\n",
    "                continue\n",
    "\n",
    "            mask = np.ones(n_classes, dtype=bool)\n",
    "            mask[c[i]] = False\n",
    "\n",
    "            # Apply mask to score matrix rows and columns\n",
    "            score[:, mask] = score[:, mask] * 0.1\n",
    "            score[mask, :] = score[mask, :] * 0.1\n",
    "\n",
    "        print scores[0]\n",
    "        return scores\n",
    "\n",
    "    def _get_neighbors_classes(self, n):\n",
    "        \"\"\"Extract unique classes for the heighborhood.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n : array-like, shape = [n_samples, n_neighbors]\n",
    "            Indices of the instance neighbors\n",
    "        \"\"\"\n",
    "        n_classes = len(self.classes_)\n",
    "\n",
    "        # Set limits to explore the neighborhood\n",
    "        lower_bound = n_classes * 3\n",
    "        upper_bound = n_classes * 6\n",
    "\n",
    "        # Go throught the neighborhood while there is only one class or the\n",
    "        # upper limit is not reached\n",
    "        for x in range(lower_bound, upper_bound):\n",
    "            neighbors_classes = np.unique(self.y[n[:x]])\n",
    "\n",
    "            # Exit the loop if we have found more classes in the neighborhood\n",
    "            if len(neighbors_classes) > 1:\n",
    "                return neighbors_classes\n",
    "        else:\n",
    "            return neighbors_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from utils.metrics import ndcg_scorer\n",
    "\n",
    "\n",
    "path = '../data/processed/'\n",
    "prefix = 'processed_'\n",
    "train_users = pd.read_csv(path + prefix + 'train_users.csv', nrows=100)\n",
    "\n",
    "train_users.fillna(-1, inplace=True)\n",
    "y_train = train_users['country_destination']\n",
    "train_users.drop(['country_destination', 'id'], axis=1, inplace=True)\n",
    "\n",
    "x_train = train_users.values\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y_train = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=1)\n",
    "clf = CustomOneVsOneClassifier(xgb, strategy='dynamic_vote', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.48333949  0.48750263  0.04900013  0.04833395  0.52271163\n",
      "   0.5427525   0.49000132]\n",
      " [ 0.51666051  0.          0.52689707  0.05        0.05        0.54376525\n",
      "   0.54291737  0.5       ]\n",
      " [ 0.51249737  0.47310293  0.          0.05        0.04731029  0.52996403\n",
      "   0.48750263  0.47003597]\n",
      " [ 0.05099987  0.05        0.05        0.          0.005       0.05451151\n",
      "   0.0540818   0.05      ]\n",
      " [ 0.05166605  0.05        0.05268971  0.005       0.          0.05437652\n",
      "   0.05429174  0.05      ]\n",
      " [ 0.47728837  0.45623475  0.47003597  0.04548849  0.04562348  0.\n",
      "   0.48001063  0.4580985 ]\n",
      " [ 0.4572475   0.45708263  0.51249737  0.0459182   0.04570826  0.51998937\n",
      "   0.          0.45918196]\n",
      " [ 0.50999868  0.5         0.52996403  0.05        0.05        0.5419015\n",
      "   0.54081804  0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.57635834,  2.4697598 ,  2.62958679,  0.29540682,  0.29197597,\n",
       "         2.76721981,  2.70237471,  2.47731776],\n",
       "       [ 1.63032494,  0.20197598,  1.62167647,  0.20241042,  0.20197597,\n",
       "         1.79159966,  1.80730478,  0.20273178],\n",
       "       [ 0.21173595,  0.20347543,  1.72978458,  0.2033103 ,  1.5847542 ,\n",
       "         1.73135206,  1.79195583,  0.20363166],\n",
       "       [ 0.26168433,  0.24847543,  2.14272932,  0.2483103 ,  2.0347542 ,\n",
       "         2.23910143,  2.2886644 ,  2.0662806 ],\n",
       "       [ 2.11735952,  0.24697598,  2.13073044,  0.24741042,  2.01975974,\n",
       "         2.20179253,  2.31823959,  0.24773178],\n",
       "       [ 0.2510846 ,  0.24847543,  2.09158839,  2.1081821 ,  0.24847542,\n",
       "         2.2445216 ,  2.27139187,  2.0662806 ],\n",
       "       [ 2.05784286,  0.24697598,  2.16521057,  0.24942401,  2.01975974,\n",
       "         2.24412825,  2.29593041,  0.25072818],\n",
       "       [ 2.07988299,  0.24697598,  2.16521057,  0.24942401,  2.01975974,\n",
       "         2.22208813,  2.29593041,  0.25072818],\n",
       "       [ 2.05784286,  0.24697598,  2.16521057,  0.24942401,  2.01975974,\n",
       "         2.24412825,  2.29593041,  0.25072818],\n",
       "       [ 2.05784286,  0.24697598,  2.16521057,  0.25192193,  2.01975974,\n",
       "         2.24163034,  2.29593041,  0.25072818],\n",
       "       [ 1.63032411,  0.20439672,  0.2130364 ,  0.20961869,  1.59396716,\n",
       "         1.79102419,  1.81190455,  0.20572818],\n",
       "       [ 2.05784286,  0.24697598,  2.16521057,  0.24741042,  2.01975974,\n",
       "         2.24614184,  2.29593041,  0.25072818],\n",
       "       [ 0.25328861,  0.24847543,  2.1365356 ,  2.06306704,  0.24847542,\n",
       "         2.24248543,  2.27139187,  2.0662806 ],\n",
       "       [ 1.63032411,  0.20439672,  0.2130364 ,  0.20510718,  1.59396716,\n",
       "         1.7955357 ,  1.81190455,  0.20572818],\n",
       "       [ 2.05784286,  0.24697598,  2.13036403,  0.24741042,  2.01975974,\n",
       "         2.2586792 ,  2.31823959,  0.25072818],\n",
       "       [ 2.07988299,  0.24697598,  2.17531124,  0.24741042,  2.01975974,\n",
       "         2.19169187,  2.31823959,  0.25072818],\n",
       "       [ 0.29758405,  2.48475426,  2.56579576,  2.51306704,  0.29347542,\n",
       "         2.80898941,  2.73005347,  2.5162806 ],\n",
       "       [ 1.5928484 ,  0.20197598,  1.65615661,  0.20241042,  0.20197597,\n",
       "         1.76929048,  1.82961396,  0.20572818],\n",
       "       [ 0.29758405,  2.48475426,  2.59575979,  2.51306704,  0.29347542,\n",
       "         2.77902538,  2.7600175 ,  2.48631657],\n",
       "       [ 1.61488853,  0.20197598,  1.7544041 ,  0.20241042,  0.20197597,\n",
       "         1.75460038,  1.72701285,  0.20273178],\n",
       "       [ 0.29978806,  2.48475426,  2.64070699,  2.51306704,  0.29347542,\n",
       "         2.73187416,  2.7600175 ,  2.48631657],\n",
       "       [ 1.61488853,  0.20197598,  1.70410022,  0.20241042,  0.20197597,\n",
       "         1.70230314,  1.82961396,  0.20273178],\n",
       "       [ 2.05784286,  0.24697598,  2.13336043,  0.24741042,  2.01975974,\n",
       "         2.28098839,  2.29593041,  0.24773178],\n",
       "       [ 0.29758405,  2.48475426,  2.63515422,  2.51306704,  0.29347542,\n",
       "         2.80898941,  2.69065903,  2.48631657],\n",
       "       [ 2.05784286,  0.24697598,  2.13336043,  0.24741042,  2.01975974,\n",
       "         2.28098839,  2.29593041,  0.24773178],\n",
       "       [ 1.5928484 ,  0.20197598,  1.70945689,  0.20241042,  0.20197597,\n",
       "         1.83156237,  1.71703819,  0.20273178],\n",
       "       [ 0.29758405,  2.48475426,  2.63515422,  2.51306704,  0.29347542,\n",
       "         2.79901475,  2.70063369,  2.48631657],\n",
       "       [ 1.5928484 ,  0.20197598,  1.65915301,  0.20241042,  0.20197597,\n",
       "         1.79159966,  1.80730478,  0.20273178],\n",
       "       [ 2.07988299,  0.24697598,  2.17830764,  0.24741042,  2.01975974,\n",
       "         2.21400105,  2.29593041,  0.24773178],\n",
       "       [ 2.07988299,  0.24697598,  2.17830764,  0.24741042,  2.01975974,\n",
       "         2.21400105,  2.29593041,  0.24773178],\n",
       "       [ 2.0953194 ,  0.24697598,  2.13073044,  0.24741042,  2.01975974,\n",
       "         2.27671715,  2.2653551 ,  0.24773178],\n",
       "       [ 1.65236506,  0.20197598,  1.63110432,  0.20241042,  0.20197597,\n",
       "         1.790707  ,  1.77672947,  0.20273178],\n",
       "       [ 1.63032494,  0.20197598,  1.62167647,  0.20241042,  0.20197597,\n",
       "         1.82217497,  1.77672947,  0.20273178],\n",
       "       [ 1.63032494,  0.20197598,  1.63258591,  0.20241042,  0.20197597,\n",
       "         1.83156237,  1.75643263,  0.20273178],\n",
       "       [ 0.21173595,  0.20347543,  1.72978458,  0.2033103 ,  1.5847542 ,\n",
       "         1.78423655,  1.73907134,  0.20363166],\n",
       "       [ 0.20953194,  0.20347543,  1.69197807,  0.2033103 ,  1.5847542 ,\n",
       "         1.78644056,  1.77687785,  0.20363166],\n",
       "       [ 1.65236506,  0.20197598,  1.63110432,  0.20241042,  0.20197597,\n",
       "         1.790707  ,  1.77672947,  0.20273178],\n",
       "       [ 1.63032494,  0.20197598,  1.62167647,  0.20241042,  0.20197597,\n",
       "         1.82217497,  1.77672947,  0.20273178],\n",
       "       [ 3.01331702,  2.9197598 ,  3.0307645 ,  2.95406823,  0.33697597,\n",
       "         3.26930196,  3.24849476,  2.92731776],\n",
       "       [ 0.16303249,  0.15847543,  1.1829241 ,  0.1583103 ,  0.15847542,\n",
       "         1.33189838,  1.28825222,  0.15863166],\n",
       "       [ 0.16303249,  0.15847543,  1.19383354,  0.1583103 ,  0.15847542,\n",
       "         1.34128579,  1.26795537,  0.15863166],\n",
       "       [ 0.16523651,  0.15847543,  1.19235195,  0.1583103 ,  0.15847542,\n",
       "         1.28969122,  1.31882752,  0.15863166],\n",
       "       [ 1.65236506,  0.20197598,  1.64201376,  0.20241042,  0.20197597,\n",
       "         1.77013037,  1.78639666,  0.20273178],\n",
       "       [ 2.55431821,  2.4697598 ,  2.5807645 ,  0.29540682,  0.29197597,\n",
       "         2.80866244,  2.73179449,  2.47731776],\n",
       "       [ 0.29978806,  2.48475426,  2.61074296,  2.5581821 ,  0.29347542,\n",
       "         2.6867591 ,  2.7600175 ,  2.5162806 ],\n",
       "       [ 1.63032494,  0.20197598,  1.65652302,  0.20241042,  0.20197597,\n",
       "         1.78732843,  1.77672947,  0.20273178],\n",
       "       [ 2.59906997,  2.4697598 ,  2.62958679,  0.29540682,  0.29197597,\n",
       "         2.74450818,  2.70237471,  2.47731776],\n",
       "       [ 2.55431821,  2.4697598 ,  2.5807645 ,  0.29540682,  0.29197597,\n",
       "         2.80866244,  2.73179449,  2.47731776],\n",
       "       [ 2.55431821,  2.4697598 ,  2.62015894,  0.29540682,  0.29197597,\n",
       "         2.80866244,  2.69240006,  2.47731776],\n",
       "       [ 1.63032494,  0.20197598,  1.62167647,  0.20241042,  0.20197597,\n",
       "         1.82217497,  1.77672947,  0.20273178],\n",
       "       [ 1.63032494,  0.20197598,  1.62167647,  0.20241042,  0.20197597,\n",
       "         1.79159966,  1.80730478,  0.20273178],\n",
       "       [ 2.59906997,  2.4697598 ,  2.60261916,  2.50406823,  0.29197597,\n",
       "         2.74740038,  2.70237471,  0.29273178],\n",
       "       [ 1.63032494,  0.20197598,  1.62167647,  0.20241042,  0.20197597,\n",
       "         1.79159966,  1.80730478,  0.20273178],\n",
       "       [ 1.63032494,  0.20197598,  1.63258591,  0.20241042,  0.20197597,\n",
       "         1.83156237,  1.75643263,  0.20273178],\n",
       "       [ 1.63032494,  0.20197598,  1.65652302,  0.20241042,  0.20197597,\n",
       "         1.75675312,  1.80730478,  0.20273178],\n",
       "       [ 2.14007116,  2.0197598 ,  2.11622112,  0.24741042,  0.24697597,\n",
       "         2.23680746,  2.27502229,  0.24773178],\n",
       "       [ 1.68557481,  0.20197598,  1.69432953,  0.20241042,  0.20197597,\n",
       "         1.75675312,  1.71424839,  0.20273178],\n",
       "       [ 2.65431984,  2.4697598 ,  2.60261916,  2.50406823,  0.29197597,\n",
       "         2.74740038,  2.64712484,  0.29273178],\n",
       "       [ 1.73032657,  0.20197598,  1.65652302,  0.20241042,  0.20197597,\n",
       "         1.71200136,  1.75205491,  0.20273178],\n",
       "       [ 2.60956808,  2.4697598 ,  2.59319131,  2.50406823,  0.29197597,\n",
       "         2.81155464,  2.63715019,  0.29273178],\n",
       "       [ 2.65431984,  2.4697598 ,  2.60261916,  2.50406823,  0.29197597,\n",
       "         2.74740038,  2.64712484,  0.29273178],\n",
       "       [ 1.68557481,  0.20197598,  1.62167647,  0.20241042,  0.20197597,\n",
       "         1.82217497,  1.7214796 ,  0.20273178],\n",
       "       [ 2.60956808,  2.4697598 ,  2.55379688,  2.50406823,  0.29197597,\n",
       "         2.81155464,  2.67654462,  0.29273178],\n",
       "       [ 2.65431984,  2.4697598 ,  2.56322472,  2.50406823,  0.29197597,\n",
       "         2.727411  ,  2.70650865,  0.29273178],\n",
       "       [ 1.73032657,  0.20197598,  1.63110432,  0.20241042,  0.20197597,\n",
       "         1.76799536,  1.7214796 ,  0.20273178],\n",
       "       [ 1.73032657,  0.20197598,  1.63110432,  0.20241042,  0.20197597,\n",
       "         1.76799536,  1.7214796 ,  0.20273178],\n",
       "       [ 2.65431984,  2.4697598 ,  2.56322472,  2.50406823,  0.29197597,\n",
       "         2.727411  ,  2.70650865,  0.29273178],\n",
       "       [ 0.2510846 ,  0.24847543,  2.09158839,  2.1081821 ,  0.24847542,\n",
       "         2.2445216 ,  2.27139187,  2.0662806 ],\n",
       "       [ 0.25328861,  0.24847543,  2.17593004,  2.1081821 ,  0.24847542,\n",
       "         2.21735975,  2.21200806,  2.0662806 ],\n",
       "       [ 0.2510846 ,  0.24847543,  2.09158839,  2.08320292,  0.24847542,\n",
       "         2.26950077,  2.27139187,  2.0662806 ],\n",
       "       [ 0.2510846 ,  0.24847543,  2.09158839,  2.1081821 ,  0.24847542,\n",
       "         2.2445216 ,  2.27139187,  2.0662806 ],\n",
       "       [ 2.05784286,  0.24697598,  2.13036403,  0.24942401,  2.01975974,\n",
       "         2.2789748 ,  2.29593041,  0.25072818],\n",
       "       [ 2.05784286,  0.24697598,  2.14127347,  0.24942401,  2.01975974,\n",
       "         2.31893751,  2.24505826,  0.25072818],\n",
       "       [ 0.2510846 ,  0.24847543,  2.09158839,  2.1081821 ,  0.24847542,\n",
       "         2.27448563,  2.24142784,  2.0662806 ],\n",
       "       [ 2.05784286,  0.24697598,  2.20301709,  0.25192193,  2.01975974,\n",
       "         2.24163034,  2.2581239 ,  0.25072818],\n",
       "       [ 2.07988299,  0.24697598,  2.17531124,  0.25192193,  2.01975974,\n",
       "         2.20948955,  2.29593041,  0.25072818],\n",
       "       [ 2.05784286,  0.24697598,  2.16521057,  0.25192193,  2.01975974,\n",
       "         2.24163034,  2.29593041,  0.25072818],\n",
       "       [ 1.63032411,  0.20439672,  0.2130364 ,  0.20712077,  1.59396716,\n",
       "         1.79352211,  1.81190455,  0.20572818],\n",
       "       [ 0.25328861,  0.24847543,  2.17593004,  2.1081821 ,  0.24847542,\n",
       "         2.21735975,  2.21200806,  2.0662806 ],\n",
       "       [ 1.5928484 ,  0.20197598,  1.66706605,  0.20241042,  0.20197597,\n",
       "         1.83156237,  1.75643263,  0.20572818],\n",
       "       [ 0.29758405,  2.48475426,  2.56579576,  2.51306704,  0.29347542,\n",
       "         2.77902538,  2.7600175 ,  2.5162806 ],\n",
       "       [ 2.05784286,  0.24697598,  2.13036403,  0.24741042,  2.01975974,\n",
       "         2.2586792 ,  2.31823959,  0.25072818],\n",
       "       [ 0.29978806,  2.48475426,  2.6501374 ,  2.51306704,  0.29347542,\n",
       "         2.75186353,  2.70063369,  2.5162806 ],\n",
       "       [ 0.29758405,  2.48475426,  2.56579576,  2.51306704,  0.29347542,\n",
       "         2.80898941,  2.73005347,  2.5162806 ],\n",
       "       [ 1.5928484 ,  0.20197598,  1.65615661,  0.20241042,  0.20197597,\n",
       "         1.76929048,  1.82961396,  0.20572818],\n",
       "       [ 2.07988299,  0.24697598,  2.17531124,  0.24741042,  2.01975974,\n",
       "         2.19169187,  2.31823959,  0.25072818],\n",
       "       [ 0.20578429,  0.20347543,  1.69572572,  0.2033103 ,  1.5847542 ,\n",
       "         1.73355607,  1.82976234,  0.20363166],\n",
       "       [ 2.07988299,  0.24697598,  2.17830764,  0.24741042,  2.01975974,\n",
       "         2.19169187,  2.31823959,  0.24773178],\n",
       "       [ 1.5928484 ,  0.20197598,  1.67006245,  0.20241042,  0.20197597,\n",
       "         1.83156237,  1.75643263,  0.20273178],\n",
       "       [ 1.5928484 ,  0.20197598,  1.67006245,  0.20241042,  0.20197597,\n",
       "         1.80159834,  1.78639666,  0.20273178],\n",
       "       [ 0.20578429,  0.20347543,  1.73353223,  0.2033103 ,  1.5847542 ,\n",
       "         1.73355607,  1.79195583,  0.20363166],\n",
       "       [ 2.07988299,  0.24697598,  2.17830764,  0.24741042,  2.01975974,\n",
       "         2.19169187,  2.31823959,  0.24773178],\n",
       "       [ 0.29758405,  2.48475426,  2.63515422,  2.51306704,  0.29347542,\n",
       "         2.80898941,  2.69065903,  2.48631657],\n",
       "       [ 1.5928484 ,  0.20197598,  1.67006245,  0.20241042,  0.20197597,\n",
       "         1.80159834,  1.78639666,  0.20273178],\n",
       "       [ 0.20578429,  0.20347543,  1.73353223,  0.2033103 ,  1.5847542 ,\n",
       "         1.73355607,  1.79195583,  0.20363166],\n",
       "       [ 0.20578429,  0.20347543,  1.69572572,  0.2033103 ,  1.5847542 ,\n",
       "         1.73355607,  1.82976234,  0.20363166],\n",
       "       [ 2.07988299,  0.24697598,  2.17830764,  0.24741042,  2.01975974,\n",
       "         2.19169187,  2.31823959,  0.24773178],\n",
       "       [ 0.29758405,  2.48475426,  2.59575979,  2.51306704,  0.29347542,\n",
       "         2.80898941,  2.73005347,  2.48631657],\n",
       "       [ 1.5928484 ,  0.20197598,  1.65915301,  0.20241042,  0.20197597,\n",
       "         1.82217497,  1.77672947,  0.20273178],\n",
       "       [ 1.5928484 ,  0.20197598,  1.65915301,  0.20241042,  0.20197597,\n",
       "         1.82217497,  1.77672947,  0.20273178]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, encoded_y_train)\n",
    "clf.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(x_train), n_folds=5, random_state=42)\n",
    "score = cross_val_score(clf, x_train, encoded_y_train, cv=kf, scoring=ndcg_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752571839219\n"
     ]
    }
   ],
   "source": [
    "print score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754870862819\n"
     ]
    }
   ],
   "source": [
    "print score.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
