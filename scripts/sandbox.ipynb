{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from utils.metrics import ndcg_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Multiclass and multilabel classification strategies.\n",
    "\n",
    "This module implements an one-vs-one multiclass learning algorithm that uses\n",
    "SMOTE algorithm to over sample the minority class in each fit.\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import _fit_binary, check_is_fitted\n",
    "from sklearn.multiclass import _ovr_decision_function, _predict_binary\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from utils.unbalanced_dataset import SMOTE, SMOTEENN, OverSampler\n",
    "from utunbalanced_dataset import UnderSampler, TomekLinks\n",
    "\n",
    "\n",
    "def _score_matrix(probabilities, n_classes):\n",
    "    \"\"\"Create a probability matrix representing the probability of each class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    probabilities : array, shape = [n_classifiers]\n",
    "        Vector containing the predicted probabilities for the positive class\n",
    "        for each classifier.\n",
    "    n_classes : int\n",
    "        Number of classes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    probability_matrix : array of shape = [n_classes, n_classes]\n",
    "        The class probabilities of the input sample as an antisymetric matrix.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> probabilities = [0.9, 0.8, 0.2, 0.5, 0.3, 0.1]\n",
    "    >>> _score_matrix(probabilities, 4)\n",
    "    array([[ 0. ,  0.9,  0.8,  0.2],\n",
    "           [ 0.1,  0. ,  0.5,  0.3],\n",
    "           [ 0.2,  0.5,  0. ,  0.1],\n",
    "           [ 0.8,  0.7,  0.9,  0. ]])\n",
    "    \"\"\"\n",
    "    # Make empty matrix\n",
    "    matrix = np.zeros((n_classes, n_classes))\n",
    "\n",
    "    # Fill upper triangle with the vector\n",
    "    matrix[np.triu_indices(n_classes, 1)] = probabilities\n",
    "\n",
    "    # Fill lower triangle with the difference to one of the upper one\n",
    "    for i in range(n_classes):\n",
    "        for j in range(i, n_classes):\n",
    "            matrix[j][i] = 1 - matrix[i][j]\n",
    "\n",
    "    # Set diagonal to zero\n",
    "    np.fill_diagonal(matrix, 0)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def _sample_values(X, y, method=None, ratio=1, verbose=False):\n",
    "    \"\"\"Performs any kind of sampling(over and under).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape = [n_samples, n_features]\n",
    "        Data.\n",
    "    y : array, shape = [n_samples]\n",
    "        Target.\n",
    "    method : str, optional default: None\n",
    "        Over or under smapling method.\n",
    "    ratio: float\n",
    "        Unbalanced class ratio.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X, y : tuple\n",
    "        Sampled X and y.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Add kwargs\n",
    "    if method == 'SMOTE':\n",
    "        sampler = SMOTE(ratio=ratio, verbose=verbose)\n",
    "\n",
    "    elif method == 'SMOTEENN':\n",
    "        ratio = ratio * 0.3\n",
    "        sampler = SMOTEENN(ratio=ratio, verbose=verbose)\n",
    "\n",
    "    elif method == 'random_over_sample':\n",
    "        sampler = OverSampler(ratio=ratio, verbose=verbose)\n",
    "\n",
    "    elif method == 'random_under_sample':\n",
    "        sampler = UnderSampler(verbose=verbose)\n",
    "\n",
    "    elif method == 'random_over_sample':\n",
    "        sampler = TomekLinks(ratio=ratio, verbose=verbose)\n",
    "\n",
    "    return sampler.fit_transform(X, y)\n",
    "\n",
    "\n",
    "def _fit_ovo_binary(estimator, X, y, i, j, sampling=None, verbose=False):\n",
    "    \"\"\"Fit a single binary estimator (one-vs-one).\"\"\"\n",
    "    cond = np.logical_or(y == i, y == j)\n",
    "    y = y[cond]\n",
    "    y_binary = np.empty(y.shape, np.int)\n",
    "    y_binary[y == i] = 0\n",
    "    y_binary[y == j] = 1\n",
    "    ind = np.arange(X.shape[0])\n",
    "\n",
    "    X_values = X[ind[cond]]\n",
    "    y_values = y_binary\n",
    "\n",
    "    if sampling:\n",
    "        ones = np.count_nonzero(y_values == 1)\n",
    "        zeros = np.count_nonzero(y_values == 0)\n",
    "        ratio = abs(ones - zeros) / min(ones, zeros)\n",
    "        X_values, y_values = _sample_values(\n",
    "            X_values, y_values, method=sampling, ratio=ratio)\n",
    "\n",
    "    return _fit_binary(estimator, X_values, y_values, classes=[i, j])\n",
    "\n",
    "\n",
    "class CustomOneVsOneClassifier(OneVsOneClassifier):\n",
    "    \"\"\"One-vs-one multiclass strategy.\n",
    "\n",
    "    This strategy consists in fitting one classifier per class pair.\n",
    "    At prediction time, the class which received the most votes is selected.\n",
    "\n",
    "    Requires to fit `n_classes * (n_classes - 1) / 2` classifiers.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    estimators_ : list of `n_classes * (n_classes - 1) / 2` estimators\n",
    "        Estimators used for predictions.\n",
    "    classes_ : numpy array of shape [n_classes]\n",
    "        Array containing labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimator, n_jobs=1, sampling=None,\n",
    "                 strategy='vote', verbose=False):\n",
    "        \"\"\"Init method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator : estimator object\n",
    "            An estimator object implementing fit and one of decision_function\n",
    "            or predict_proba.\n",
    "        n_jobs : int, optional, default: 1\n",
    "            The number of jobs to use. If -1 all CPUs are used.\n",
    "            If 1 is given, no parallel computing code is used at all, which is\n",
    "            useful for debugging. For n_jobs below -1, (n_cpus + 1 + n_jobs)\n",
    "            are used. Thus for n_jobs = -2, all CPUs but one are used.\n",
    "        sampling : str, optional default: None\n",
    "            Samplig method to use when fitting each estimator.\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.n_jobs = n_jobs\n",
    "        self.sampling = sampling\n",
    "        self.verbose = verbose\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities for X.\n",
    "\n",
    "        The predicted class probabilities of an input sample is the same as\n",
    "        the result of decision_function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
    "            such arrays if n_outputs > 1.\n",
    "            The class probabilities of the input samples.\n",
    "        \"\"\"\n",
    "        return self.decision_function(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit underlying estimators.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : (sparse) array-like, shape = [n_samples, n_features]\n",
    "            Data.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Multi-class targets.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "\n",
    "        valid_strategies = ('vote', 'weighted_vote',\n",
    "                            'dynamic_vote', 'relative_competence')\n",
    "        if self.strategy not in valid_strategies:\n",
    "            raise ValueError('Strategy %s is not valid. '\n",
    "                             'Allowed values are: vote, weighted_vote,'\n",
    "                             ' dynamic_vote and relative_competence.'\n",
    "                             % (self.strategy))\n",
    "\n",
    "        if self.sampling not in ('SMOTE', 'SMOTEENN', 'OverSampler',\n",
    "                                 'UnderSampler', 'TomekLinks', None):\n",
    "            raise ValueError('Sampling %s is not valid. '\n",
    "                             'Allowed values are: SMOTE, SMOTEENN, '\n",
    "                             'OverSampler, UnderSampler, TomekLinks and None'\n",
    "                             % (self.sampling))\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_classes = self.classes_.shape[0]\n",
    "\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_ovo_binary)(\n",
    "                self.estimator, X, y, self.classes_[i], self.classes_[j],\n",
    "                sampling=self.sampling, verbose=self.verbose\n",
    "            ) for i in range(n_classes) for j in range(i + 1, n_classes))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Decision function for the CustomOneVsOneClassifier.\n",
    "\n",
    "        By default, the decision values for the samples are computed by adding\n",
    "        the normalized sum of pair-wise classification confidence levels to the\n",
    "        votes in order to disambiguate between the decision values when the\n",
    "        votes for all the classes are equal leading to a tie.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Y : array-like, shape = [n_samples, n_classes]\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'estimators_')\n",
    "\n",
    "        predictions = np.vstack([est.predict(X) for est in self.estimators_]).T\n",
    "        confidences = np.vstack([_predict_binary(est, X)\n",
    "                                 for est in self.estimators_]).T\n",
    "\n",
    "        n_clases = len(self.classes_)\n",
    "\n",
    "        if self.strategy in ('weighted_vote', 'dynamic_vote',\n",
    "                             'relative_competence'):\n",
    "\n",
    "            scores = [_score_matrix(c, n_clases) for c in confidences]\n",
    "\n",
    "            if self.strategy == 'dynamic_vote':\n",
    "                # scores = [_dinamic_ovo(m, x, y)\n",
    "                #           for m, x, y in zip(scores, X, self.y)]\n",
    "                raise NotImplementedError(\n",
    "                    'Strategy dynamic_vote not implemented.')\n",
    "\n",
    "            elif self.strategy == 'relative_competence':\n",
    "                raise NotImplementedError(\n",
    "                    'Strategy relative_competence not implemented.')\n",
    "\n",
    "            votes = np.vstack([np.sum(m, axis=0) for m in scores])\n",
    "\n",
    "            return votes\n",
    "\n",
    "        elif self.strategy == 'vote':\n",
    "            return _ovr_decision_function(predictions, confidences,\n",
    "                                          n_clases)\n",
    "\n",
    "\n",
    "def _dinamic_ovo(score_matrix, x, y):\n",
    "    print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_users = pd.read_csv('../data/processed/ohe_count_processed_train_users.csv', nrows=50000)\n",
    "train_users.fillna(-1, inplace=True)\n",
    "y_train = train_users['country_destination']\n",
    "train_users.drop('country_destination', axis=1, inplace=True)\n",
    "train_users.drop('id', axis=1, inplace=True)\n",
    "x_train = train_users.values\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y_train = label_encoder.fit_transform(y_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=41, n_jobs=-1)\n",
    "clf = CustomOneVsOneClassifier(rf, strategy='weighted_vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 12 [ 0  1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "classes_ = np.unique(encoded_y_train)\n",
    "n_classes = classes_.shape[0]\n",
    "print 'Classes:', n_classes, classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(x_train), n_folds=5, random_state=42)\n",
    "\n",
    "%time score = cross_val_score(clf, x_train, encoded_y_train, cv=kf, scoring=ndcg_scorer)\n",
    "\n",
    "print score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.1       ,   4.83333333,   4.        , ...,   0.8       ,\n",
       "          9.9       ,   6.5       ],\n",
       "       [  1.6       ,   5.3       ,   3.6       , ...,   1.7       ,\n",
       "          9.6       ,   7.3       ],\n",
       "       [  3.2       ,   4.9       ,   2.8       , ...,   2.1       ,\n",
       "         10.5       ,   6.8       ],\n",
       "       ..., \n",
       "       [  3.        ,   4.6       ,   4.5       , ...,   0.8       ,\n",
       "         10.35      ,   7.75      ],\n",
       "       [  2.5       ,   3.6       ,   3.5       , ...,   1.3       ,\n",
       "          9.9       ,   7.7       ],\n",
       "       [  2.2       ,   5.8       ,   3.9       , ...,   0.9       ,\n",
       "          9.8       ,   7.3       ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf.fit(x_train, encoded_y_train)\n",
    "# clf.predict_proba(x_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
