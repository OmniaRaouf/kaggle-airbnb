{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from utils.metrics import ndcg_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Multiclass and multilabel classification strategies.\n",
    "\n",
    "This file implements an one-vs-one multiclass learning algorithm that uses\n",
    "over sampling algorithms and variances of the decision function.\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import _fit_binary, check_is_fitted\n",
    "from sklearn.multiclass import _ovr_decision_function, _predict_binary\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from utils.unbalanced_dataset import SMOTE, SMOTEENN, OverSampler\n",
    "from utils.unbalanced_dataset import UnderSampler, TomekLinks\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def _score_matrix(probabilities, n_classes):\n",
    "    \"\"\"Create a probability matrix representing the probability of each class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    probabilities : array, shape = [n_classifiers]\n",
    "        Vector containing the predicted probabilities for the positive class\n",
    "        for each classifier.\n",
    "    n_classes : int\n",
    "        Number of classes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    probability_matrix : array of shape = [n_classes, n_classes]\n",
    "        The class probabilities of the input sample as an antisymetric matrix.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> probabilities = [0.9, 0.8, 0.2, 0.5, 0.3, 0.1]\n",
    "    >>> _score_matrix(probabilities, 4)\n",
    "    array([[ 0. ,  0.9,  0.8,  0.2],\n",
    "           [ 0.1,  0. ,  0.5,  0.3],\n",
    "           [ 0.2,  0.5,  0. ,  0.1],\n",
    "           [ 0.8,  0.7,  0.9,  0. ]])\n",
    "    \"\"\"\n",
    "    # Make empty matrix\n",
    "    matrix = np.zeros((n_classes, n_classes))\n",
    "\n",
    "    # Fill upper triangle with the vector\n",
    "    matrix[np.triu_indices(n_classes, 1)] = probabilities\n",
    "\n",
    "    # Fill lower triangle with the difference to one of the upper one\n",
    "    for i in range(n_classes):\n",
    "        for j in range(i, n_classes):\n",
    "            matrix[j][i] = 1 - matrix[i][j]\n",
    "\n",
    "    # Set diagonal to zero\n",
    "    np.fill_diagonal(matrix, 0)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def _sample_values(X, y, method=None, ratio=1, verbose=False):\n",
    "    \"\"\"Perform any kind of sampling(over and under).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape = [n_samples, n_features]\n",
    "        Data.\n",
    "    y : array, shape = [n_samples]\n",
    "        Target.\n",
    "    method : str, optional default: None\n",
    "        Over or under smapling method.\n",
    "    ratio: float\n",
    "        Unbalanced class ratio.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X, y : tuple\n",
    "        Sampled X and y.\n",
    "    \"\"\"\n",
    "    # TODO: Add kwargs\n",
    "    if method == 'SMOTE':\n",
    "        sampler = SMOTE(ratio=ratio, verbose=verbose)\n",
    "\n",
    "    elif method == 'SMOTEENN':\n",
    "        ratio = ratio * 0.3\n",
    "        sampler = SMOTEENN(ratio=ratio, verbose=verbose)\n",
    "\n",
    "    elif method == 'random_over_sample':\n",
    "        sampler = OverSampler(ratio=ratio, verbose=verbose)\n",
    "\n",
    "    elif method == 'random_under_sample':\n",
    "        sampler = UnderSampler(verbose=verbose)\n",
    "\n",
    "    elif method == 'TomekLinks':\n",
    "        sampler = TomekLinks(verbose=verbose)\n",
    "\n",
    "    return sampler.fit_transform(X, y)\n",
    "\n",
    "\n",
    "def _fit_ovo_binary(estimator, X, y, i, j, sampling=None, verbose=False):\n",
    "    \"\"\"Fit a single binary estimator (one-vs-one).\"\"\"\n",
    "    cond = np.logical_or(y == i, y == j)\n",
    "    y = y[cond]\n",
    "    y_binary = np.empty(y.shape, np.int)\n",
    "    y_binary[y == i] = 0\n",
    "    y_binary[y == j] = 1\n",
    "    ind = np.arange(X.shape[0])\n",
    "\n",
    "    X_values = X[ind[cond]]\n",
    "    y_values = y_binary\n",
    "\n",
    "    if sampling:\n",
    "        ones = np.count_nonzero(y_values == 1)\n",
    "        zeros = np.count_nonzero(y_values == 0)\n",
    "        ratio = abs(ones - zeros) / min(ones, zeros)\n",
    "        X_values, y_values = _sample_values(\n",
    "            X_values, y_values, method=sampling, ratio=ratio)\n",
    "\n",
    "    return _fit_binary(estimator, X_values, y_values, classes=[i, j])\n",
    "\n",
    "\n",
    "class CustomOneVsOneClassifier(OneVsOneClassifier):\n",
    "    \"\"\"\n",
    "    One-vs-one multiclass strategy.\n",
    "\n",
    "    This strategy consists in fitting one classifier per class pair.\n",
    "    At prediction time, the class which received the most votes is selected.\n",
    "\n",
    "    Requires to fit `n_classes * (n_classes - 1) / 2` classifiers.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    estimators_ : list of `n_classes * (n_classes - 1) / 2` estimators\n",
    "        Estimators used for predictions.\n",
    "    classes_ : numpy array of shape [n_classes]\n",
    "        Array containing labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimator, n_jobs=1, sampling=None,\n",
    "                 strategy='vote', verbose=False):\n",
    "        \"\"\"Init method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator : estimator object\n",
    "            An estimator object implementing fit and one of decision_function\n",
    "            or predict_proba.\n",
    "        n_jobs : int, optional, default: 1\n",
    "            The number of jobs to use. If -1 all CPUs are used.\n",
    "            If 1 is given, no parallel computing code is used at all, which is\n",
    "            useful for debugging. For n_jobs below -1, (n_cpus + 1 + n_jobs)\n",
    "            are used. Thus for n_jobs = -2, all CPUs but one are used.\n",
    "        sampling : str, optional default: None\n",
    "            Samplig method to use when fitting each estimator.\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.n_jobs = n_jobs\n",
    "        self.sampling = sampling\n",
    "        self.verbose = verbose\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities for X.\n",
    "\n",
    "        The predicted class probabilities of an input sample is the same as\n",
    "        the result of decision_function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
    "            such arrays if n_outputs > 1.\n",
    "            The class probabilities of the input samples.\n",
    "        \"\"\"\n",
    "        return self.decision_function(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit underlying estimators.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : (sparse) array-like, shape = [n_samples, n_features]\n",
    "            Data.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Multi-class targets.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        valid_strategies = ('vote', 'weighted_vote',\n",
    "                            'dynamic_vote', 'relative_competence')\n",
    "        if self.strategy not in valid_strategies:\n",
    "            raise ValueError('Strategy %s is not valid. '\n",
    "                             'Allowed values are: vote, weighted_vote,'\n",
    "                             ' dynamic_vote and relative_competence.'\n",
    "                             % (self.strategy))\n",
    "\n",
    "        if self.sampling not in ('SMOTE', 'SMOTEENN', 'random_over_sample',\n",
    "                                 'random_under_sample', 'TomekLinks', None):\n",
    "            raise ValueError('Sampling %s is not valid. '\n",
    "                             'Allowed values are: SMOTE, SMOTEENN, '\n",
    "                             'random_over_sample, random_under_sample, TomekLinks and None'\n",
    "                             % (self.sampling))\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_classes = self.classes_.shape[0]\n",
    "\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_ovo_binary)(\n",
    "                self.estimator, X, y, self.classes_[i], self.classes_[j],\n",
    "                sampling=self.sampling, verbose=self.verbose\n",
    "            ) for i in range(n_classes) for j in range(i + 1, n_classes))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Decision function for the CustomOneVsOneClassifier.\n",
    "\n",
    "        By default, the decision values for the samples are computed by adding\n",
    "        the normalized sum of pair-wise classification confidence levels to the\n",
    "        votes in order to disambiguate between the decision values when the\n",
    "        votes for all the classes are equal leading to a tie.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Y : array-like, shape = [n_samples, n_classes]\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'estimators_')\n",
    "\n",
    "        predictions = np.vstack([est.predict(X) for est in self.estimators_]).T\n",
    "        confidences = np.vstack([_predict_binary(est, X)\n",
    "                                 for est in self.estimators_]).T\n",
    "\n",
    "        n_clases = len(self.classes_)\n",
    "\n",
    "        if self.strategy in ('weighted_vote', 'dynamic_vote',\n",
    "                             'relative_competence'):\n",
    "\n",
    "            scores = [_score_matrix(c, n_clases) for c in confidences]\n",
    "\n",
    "            if self.strategy == 'dynamic_vote':\n",
    "                scores = self._dynamic_ovo(scores, X, n_clases)\n",
    "\n",
    "            elif self.strategy == 'relative_competence':\n",
    "                raise NotImplementedError(\n",
    "                    'Strategy relative_competence not implemented.')\n",
    "\n",
    "            votes = np.vstack([np.sum(m, axis=0) for m in scores])\n",
    "\n",
    "            return votes\n",
    "\n",
    "        elif self.strategy == 'vote':\n",
    "            return _ovr_decision_function(predictions, confidences,\n",
    "                                          n_clases)\n",
    "\n",
    "    def _dynamic_ovo(self, scores, x, n_classes):\n",
    "        \"\"\"Dynamic One vs One classifier selection strategy.\n",
    "\n",
    "        Dynamic classifier selection strategy for One vs One scheme tries to\n",
    "        avoid the non-competent classifiers  when their output is probably not\n",
    "        of interest considering the neighborhood of each instance to decide\n",
    "        whether a classifier may be competent or not.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        Mikel Galar, Alberto Fernandez, Edurne Barrenechea, Humberto Bustince,\n",
    "        and Francisco Herrera. Dynamic classifier selection for One-vs-One\n",
    "        strategy: Avoiding non-competent classifiers. 2013.\n",
    "        \"\"\"\n",
    "        # Select all the neighborhood\n",
    "        k = n_classes * 6\n",
    "\n",
    "        # Fit the training data\n",
    "        neigh = NearestNeighbors(n_neighbors=k, n_jobs=-1)\n",
    "        neigh.fit(self.X)\n",
    "        \n",
    "        # Compute the indices of the k neighbors for x\n",
    "        n = neigh.kneighbors(x, return_distance=False)\n",
    "\n",
    "        # Get the unique classes of each neighbors\n",
    "        c = map(self._classes, n)  \n",
    "        \n",
    "        # Select the column classes in the score matrices that appears into\n",
    "        # the neighborhood.\n",
    "        for i, score in enumerate(scores):\n",
    "            # TODO: Check c lenghts(return with 1)\n",
    "            mask = np.ones(n_classes, dtype=bool)\n",
    "            mask[c[i]] = False\n",
    "            score[:, mask] = score[:, mask] * 0.1\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def _classes(self, n):\n",
    "        n_classes = len(self.classes_)\n",
    "        lower_bound = n_classes * 3\n",
    "        upper_bound = n_classes * 6\n",
    "        \n",
    "        for x in range(lower_bound, upper_bound):\n",
    "            neighbors_classes = np.unique(self.y[n[:x]])\n",
    "            \n",
    "            if len(neighbors_classes) > 1:\n",
    "                return neighbors_classes\n",
    "        else:\n",
    "            return neighbors_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 12 [ 0  1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "train_users = pd.read_csv('../data/processed/processed_train_users.csv', nrows=10000)\n",
    "\n",
    "train_users.fillna(-1, inplace=True)\n",
    "y_train = train_users['country_destination']\n",
    "train_users.drop('country_destination', axis=1, inplace=True)\n",
    "train_users.drop('id', axis=1, inplace=True)\n",
    "x_train = train_users.values\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_y_train = label_encoder.fit_transform(y_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "rf = RandomForestClassifier(n_estimators=5, random_state=41, n_jobs=-1)\n",
    "model = SelectFromModel(rf)\n",
    "x_train = model.fit_transform(x_train, encoded_y_train)\n",
    "clf = CustomOneVsOneClassifier(rf, strategy='dynamic_vote', sampling='TomekLinks')\n",
    "\n",
    "classes_ = np.unique(encoded_y_train)\n",
    "n_classes = classes_.shape[0]\n",
    "print 'Classes:', n_classes, classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.3 s, sys: 3.16 s, total: 53.5 s\n",
      "Wall time: 2min 35s\n",
      "0.751605767364\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(len(x_train), n_folds=5, random_state=42)\n",
    "%time score = cross_val_score(clf, x_train, encoded_y_train, cv=kf, scoring=ndcg_scorer)\n",
    "print score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.27 s, sys: 604 ms, total: 2.88 s\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "# clf.fit(x_train, encoded_y_train) 0.745, 0.7500, \n",
    "# %time preds = clf.predict_proba(x_train) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
